{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APOLITICAL-SCRAPING-TASK-SUBMISSION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFoVtoPrZsjx",
        "colab_type": "text"
      },
      "source": [
        "**Part Two: Analysis**\n",
        "\n",
        "\n",
        "*   Identifying key words that tells what each article is about\n",
        "*   Grouping similar articles together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsAvw7sWaUGW",
        "colab_type": "text"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTwDCgpUZeFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 486,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy9GBF01hp4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9f007e67-75d4-4af8-95bf-4aa81a2b382c"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnNP36tHbJqg",
        "colab_type": "text"
      },
      "source": [
        "**Import articles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEKHx2rpaewI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df = pd.read_csv('apoliticalArticles.csv')"
      ],
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeuwAbJZbTLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop('Unnamed: 0', axis=1)"
      ],
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwH9fXoQba5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "ec15d997-76ac-4441-ebfc-8aeb05da52a4"
      },
      "source": [
        "data = df['Content']\n",
        "data.head()"
      ],
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Climate-related displacement and migration is ...\n",
              "1    Imagine being asked to identify and cut £140 m...\n",
              "2    Refugees in Ghana have the same legal rights a...\n",
              "3    Luxembourg recently became the first country i...\n",
              "4    This article is written by Juan Vila, director...\n",
              "Name: Content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 490
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0ZZinbpcHfe",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftWTldmAcG0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_lower_case(data):\n",
        "    return np.char.lower(data)"
      ],
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4heYC-fcSn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(data):\n",
        "    stop_words = stopwords.words('english')\n",
        "    words = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in words:\n",
        "        if w not in stop_words and len(w) > 1:\n",
        "            new_text = new_text + \" \" + w\n",
        "    return new_text\n"
      ],
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hmhd4h_cW6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(data):\n",
        "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
        "    for i in range(len(symbols)):\n",
        "        data = np.char.replace(data, symbols[i], ' ')\n",
        "        data = np.char.replace(data, \"  \", \" \")\n",
        "    data = np.char.replace(data, ',', '')\n",
        "    return data"
      ],
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewVP-HP-dXig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data.apply(lambda x: convert_lower_case(x))\n",
        "data=data.apply(lambda x: remove_stop_words(x))\n",
        "data=data.apply(lambda x: remove_punctuation(x))\n"
      ],
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1El-y1GFiBIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "42a72f77-828f-49d8-c692-f684570f3cfa"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     climate related displacement migration set gr...\n",
              "1     imagine asked identify cut £140 million budge...\n",
              "2     refugees ghana legal rights ordinary citizens...\n",
              "3     luxembourg recently became first country worl...\n",
              "4     article written juan vila director open gover...\n",
              "Name: Content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 495
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTIbiaH2oWuq",
        "colab_type": "text"
      },
      "source": [
        "**Calculate DF-IDF score of words in each article to determine words with high importance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BWoHLd0om2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tfidf.fit_transform(data)"
      ],
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0jz0C4Jrzyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "important_words = tfidf.vocabulary_"
      ],
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOQRwD4MtBbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "cee9eda7-9e1a-4308-f4a9-b8115ffbb5fc"
      },
      "source": [
        "#Top 20 Important words in the articles\n",
        "\n",
        "important_words = list(important_words.items())[:20]\n",
        "\n",
        "important_words\n"
      ],
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('climate', 447),\n",
              " ('related', 2000),\n",
              " ('displacement', 737),\n",
              " ('migration', 1525),\n",
              " ('set', 2159),\n",
              " ('greatest', 1107),\n",
              " ('challenge', 407),\n",
              " ('era', 870),\n",
              " ('communities', 488),\n",
              " ('arid', 206),\n",
              " ('semi', 2140),\n",
              " ('lands', 1369),\n",
              " ('particularly', 1713),\n",
              " ('vulnerable', 2586),\n",
              " ('effects', 800),\n",
              " ('change', 410),\n",
              " ('exposure', 926),\n",
              " ('extreme', 930),\n",
              " ('temperature', 2385),\n",
              " ('irregularity', 1324)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 498
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zMZ-4V4LdBI",
        "colab_type": "text"
      },
      "source": [
        "**Perform Topic Modelling on articles to identify the main theme of the articles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq4q2inOuTp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_features = 1000\n",
        "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features,stop_words='english')\n",
        "tf = tf_vectorizer.fit_transform(data)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "no_topics = 14\n",
        "\n",
        "# Run LDA (Latent Dirichlet allocation)\n",
        "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=500, learning_method='online', learning_offset=50.,random_state=0).fit(tf)"
      ],
      "execution_count": 499,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLVcBiOXvbGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "85d69ee4-f6f5-4d38-cc6d-3cadc908e599"
      },
      "source": [
        "# Function to display the topics and words\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    words_list = []\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print (\"Topic\", topic_idx)\n",
        "        print (\" \".join([feature_names[i]\n",
        "        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        words_list.append(\" \".join([feature_names[i]\n",
        "        # Append topic to list to visualise in wordcloud                            \n",
        "        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "    return ' '.join(words_list)\n",
        "no_top_words = 15\n",
        "topic_words = display_topics(lda, tf_feature_names, no_top_words)"
      ],
      "execution_count": 500,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0\n",
            "health refugees refugee services training status integration centres work new people migrant public states care\n",
            "Topic 1\n",
            "local regional government australia communities new job work need workforce areas migration different public leadership\n",
            "Topic 2\n",
            "developments decision said felt evidence council using solutions populations staff citizens day integration devices person\n",
            "Topic 3\n",
            "credit decision expectancy equal immediately team overhaul opportunities 10 unlike key relationship care circumstances require\n",
            "Topic 4\n",
            "council staff said deal training people change local town different values approach asked new taking\n",
            "Topic 5\n",
            "data digital public opening experience step limited working sessions team wanted spaces decisions right number\n",
            "Topic 6\n",
            "citizens source relationship developed seasonal today transportation identified solve county analysis servants face coordination felt\n",
            "Topic 7\n",
            "role social responsible remain commons million financial chronic unsplash changing regularly rapid practices crises training\n",
            "Topic 8\n",
            "data public government urban health open work environmental city individual live governments initiatives relying faced\n",
            "Topic 9\n",
            "data change cities people public transport humanitarian health evidence free city specific vulnerable problems funding\n",
            "Topic 10\n",
            "data public urban cities government digital solutions app new citizens city infrastructure economic like services\n",
            "Topic 11\n",
            "deal council said staff terms alongside strategy increased taking million local citizens approach given financial\n",
            "Topic 12\n",
            "regional faced opportunities rethink growth rights care wanted australia rate best failure host bureaucratic sources\n",
            "Topic 13\n",
            "health public data transport cities city free local new people car make number services crisis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGzuPiqhuU2K",
        "colab_type": "text"
      },
      "source": [
        "**TF-IDF (term frequency–inverse document frequency) and euclidean distance for article similarity calculation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GljVu5YE9XS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "eae33282-d676-4cbe-aa8e-68670274ccea"
      },
      "source": [
        "content_list = list(data)\n",
        "print(data)\n",
        "vectorizer = CountVectorizer()\n",
        "features = vectorizer.fit_transform(content_list).todense()\n",
        "\n",
        "for f in features:\n",
        "  print (euclidean_distances(features[1], f))\n"
      ],
      "execution_count": 501,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      climate related displacement migration set gr...\n",
            "1      imagine asked identify cut £140 million budge...\n",
            "2      refugees ghana legal rights ordinary citizens...\n",
            "3      luxembourg recently became first country worl...\n",
            "4      article written juan vila director open gover...\n",
            "5      coronavirus crisis sweeping globe health data...\n",
            "6      meanwhile refugees became settled turkey need...\n",
            "7      discover inspiring tools resources policies c...\n",
            "8      piece written nick kimber public policy profe...\n",
            "9      piece written audrey macklin professor chair ...\n",
            "10     article written madhu raghunath sector leader...\n",
            "11     opinion piece written jack archer ceo regiona...\n",
            "12     article written zachary spicer director resea...\n",
            "13     article written mathew yarger head smart citi...\n",
            "14     article written andrew phillips national mana...\n",
            "Name: Content, dtype: object\n",
            "[[57.39]]\n",
            "[[0.]]\n",
            "[[56.44]]\n",
            "[[64.61]]\n",
            "[[64.75]]\n",
            "[[74.23]]\n",
            "[[64.95]]\n",
            "[[55.43]]\n",
            "[[57.26]]\n",
            "[[68.33]]\n",
            "[[64.05]]\n",
            "[[60.61]]\n",
            "[[66.29]]\n",
            "[[70.56]]\n",
            "[[55.69]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut6iXB768Vwv",
        "colab_type": "text"
      },
      "source": [
        "# Summary of findings\n",
        "\n",
        "**Part one**\n",
        "\n",
        "I started this section by attempting to scrape the URL provided using python beautiful soup library but I faced some challenges because the page does not load HTML content directly on load. I resolved this by using python selenium library which emulates the way a user would have opened the link in the browser, this way I was able to get the HTML data I need for beautifulsoup to process. This attempt would also scale for more URL without rate limit issues.\n",
        "\n",
        "I exported the scrapped data into a CSV file for further analysis in part two.\n",
        "\n",
        "**Part Two: Analysis**\n",
        "\n",
        "In this part, I analysed the data for important words and group similar articles together.\n",
        "\n",
        "I performed data preprocessing and used TF-IDF(Term Frequency, Inverse Document Frequency) to identify words that are of high importance in the article. I identified words like \"climate\", \"migration\", \"communities\". This word shows the central idea of the articles analysed.\n",
        "\n",
        "I used Eculendean distance to determine how similar articles are to each other. we will notice that article 6 (74.23) and Article 7 (70.56) are similar. This two articles covered topics related to smart city/future city. Article 1(57.39) and Article 3(56.44) are also similar, they both cover topics about refugees."
      ]
    }
  ]
}